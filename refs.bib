@article{understandingMetadataRiley2017,
  title={Understanding metadata},
  author={Riley, Jenn},
  journal={Washington DC, United States: National Information Standards Organization (http://www.niso.org/publications/press/UnderstandingMetadata.pdf)},
  volume={23},
  pages={7--10},
  year={2017}
}

@inproceedings{roleOfMetadataInStatisticsdippo2000,
  title={The role of metadata in statistics},
  author={Dippo, Cathryn},
  booktitle={Proceedings of the Second International Conference on Establishment Surveys, 2000},
  pages={909--918},
  year={2000}
}

@inproceedings{bigDataAReviewsagiroglu2013,
  title={Big data: A review},
  author={Sagiroglu, Seref and Sinanc, Duygu},
  booktitle={2013 international conference on collaboration technologies and systems (CTS)},
  pages={42--47},
  year={2013},
  organization={IEEE}
}

@book{understandingBigDataZikopoulos2011,
  title={Understanding big data: Analytics for enterprise class hadoop and streaming data},
  author={Zikopoulos, Paul and Eaton, Chris},
  year={2011},
  publisher={McGraw-Hill Osborne Media}
}

@InProceedings{apiFirstBealieu,
author="Beaulieu, Nicole
and Dascalu, Sergiu M.
and Hand, Emily",
editor="Latifi, Shahram",
title="API-First Design: A Survey of the State of Academia and Industry",
booktitle="ITNG 2022 19th International Conference on Information Technology-New Generations",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="73--79",
abstract="The evolution of distributed and cloud-based systems has led the computing community to converge on Microservice Architecture (MSA) as a preferred solution to distributed software design. Established design methodologies applied to MSA (e.g., Data-, Model-, and Domain-Driven Design) assist in decision-making about business capacity and functionality encapsulated by the microservice. An expected result of microservice design is a well-defined Application Programming Interface (API) that facilitates the access of microservice and system capabilities. However, even with the extensive documentation and defined frameworks guiding practitioners in their execution of MSA, challenges exist in defining and exposing clean APIs. Further, the industry's current focus on maximizing business capacities exposed by distributed systems emphasizes the importance of improving API design and implementation. To this end, API-First Design is emerging as a viable approach to MSA and API design. API-First principles suggest that all capabilities of an organization and its systems are exposed via an API and that the foundation of system design is the definition of clear and well-defined APIs. A significant challenge associated with API-First Design lies in the infancy of the topic and the necessity for peer-reviewed research defining guidelines for adoption and a baseline for future research. This paper seeks to move the state of the API-First Design methodology forward by exploring publications of the academic community and grey literature available on the topic. The paper concludes with a discussion about future research opportunities that may advance the understanding and adoption of API-First Design.",
isbn="978-3-030-97652-1"
}

@inproceedings{apacheRangerMultiLayerdGuptaMaanak2017,
author = {Gupta, Maanak and Patwa, Farhan and Benson, James and Sandhu, Ravi},
title = {Multi-Layer Authorization Framework for a Representative Hadoop Ecosystem Deployment},
year = {2017},
isbn = {9781450347020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078861.3084173},
doi = {10.1145/3078861.3084173},
abstract = {Apache Hadoop is a predominant software framework to store and process vast amount of data, produced in varied formats. Data stored in Hadoop multi-tenant data lake often includes sensitive data such as social security numbers, intelligence sources and medical particulars, which should only be accessed by legitimate users. Apache Ranger and Apache Sentry are important authorization systems providing fine-grained access control across several Hadoop ecosystem services. In this paper, we provide a comprehensive explanation for the authorization framework offered by Hadoop ecosystem, incorporating core Hadoop 2.x native access control features and capabilities offered by Apache Ranger, with prime focus on data services including Apache Hive and Hadoop 2.x core services. A multi-layer authorization system is discussed and demonstrated, reflecting access control for services, data, applications and infrastructure resources inside a representative Hadoop ecosystem instance. A concrete use case is discussed to underline the application of aforementioned access control points. We use Hortonworks Hadoop distribution HDP 2.5 to exhibit this multi-layer access control framework.},
booktitle = {Proceedings of the 22nd ACM on Symposium on Access Control Models and Technologies},
pages = {183–190},
numpages = {8},
keywords = {data lake, access control, role based, hadoop ecosystem, attributes, object tags, big data},
location = {Indianapolis, Indiana, USA},
series = {SACMAT '17 Abstracts}
}

@inproceedings{apacheRangerAccessControlModelGuptaMaanak2017,
author = {Gupta, Maanak and Patwa, Farhan and Sandhu, Ravi},
title = {POSTER: Access Control Model for the Hadoop Ecosystem},
year = {2017},
isbn = {9781450347020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078861.3084164},
doi = {10.1145/3078861.3084164},
abstract = {Apache Hadoop is an important framework for fault-tolerant and distributed storage and processing of Big Data. Hadoop core platform along with other open-source tools such as Apache Hive, Storm, HBase offer an ecosystem to enable users to fully harness Big Data potential. Apache Ranger and Apache Sentry provide access control capabilities to several ecosystem components by offering centralized policy administration and enforcement through plugins. In this work we discuss the access control model for Hadoop ecosystem (referred as HeAC) used by Apache Ranger (release 0.6) and Sentry (release 1.7.0) along with Hadoop 2.x native authorization capabilities. This multi-layer model provides several access enforcement points to restrict unauthorized users to cluster resources. We further outline some preliminary approaches to extend the HeAC model consistent with widely accepted access control models.},
booktitle = {Proceedings of the 22nd ACM on Symposium on Access Control Models and Technologies},
pages = {125–127},
numpages = {3},
keywords = {attributes, data lake, hadoop ecosystem, role based, access control, big data, groups hierarchy, object tags},
location = {Indianapolis, Indiana, USA},
series = {SACMAT '17 Abstracts}
}

@InProceedings{rangerHealhcareRangarajan2018,
author="Rangarajan, Sarathkumar
and Liu, Huai
and Wang, Hua
and Wang, Chuan-Long",
editor="Beheshti, Amin
and Hashmi, Mustafa
and Dong, Hai
and Zhang, Wei Emma",
title="Scalable Architecture for Personalized Healthcare Service Recommendation Using Big Data Lake",
booktitle="Service Research and Innovation",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="65--79",
abstract="The personalized health care service utilizes the relational patient data and big data analytics to tailor the medication recommendations. However, most of the health care data are in unstructured form and it consumes a lot of time and effort to pull them into relational form. This study proposes a novel data lake architecture to reduce the data ingestion time and improve the precision of healthcare analytics. It also removes the data silos and enhances the analytics by allowing the connectivity to the third-party data providers (such as clinical lab results, chemist, insurance company, etc.). The data lake architecture uses the Hadoop Distributed File System (HDFS) to provide the storage for both structured and unstructured data. This study uses K-means clustering algorithm to find the patient clusters with similar health conditions. Subsequently, it employs a support vector machine to find the most successful healthcare recommendations for the each cluster. Our experiment results demonstrate the ability of data lake to reduce the time for ingesting data from various data vendors regardless of its format. Moreover, it is evident that the data lake poses the potential to generate clusters of patients more precisely than the existing approaches. It is obvious that the data lake provides an unified storage location for the data in its native format. It can also improve the personalized healthcare medication recommendations by removing the data silos.",
isbn="978-3-319-76587-7"
}

@article{rangerTelecomAhmad2019,
  title={Customer churn prediction in telecom using machine learning in big data platform},
  author={Ahmad, Abdelrahim Kasem and Jafar, Assef and Aljoumaa, Kadan},
  journal={Journal of Big Data},
  volume={6},
  number={1},
  pages={1--24},
  year={2019},
  publisher={Springer}
}

@article{bigDataSecurityTankard20125,
title = {Big data security},
journal = {Network Security},
volume = {2012},
number = {7},
pages = {5-8},
year = {2012},
issn = {1353-4858},
doi = {https://doi.org/10.1016/S1353-4858(12)70063-6},
url = {https://www.sciencedirect.com/science/article/pii/S1353485812700636},
author = {Colin Tankard},
abstract = {The term big data has come into use recently to refer to the ever-increasing amount of information that organisations are storing, processing and analysing, owing to the growing number of information sources in use. According to research conducted by IDC, there were 1.8 zettabytes (1.8 trillion gigabytes) of information created and replicated in 2011 alone and that amount is doubling every two years.1 Within the next decade, the amount of information managed by enterprise datacentres will grow by 50 times, whereas the number of IT professionals will expand by just 1.5 times. Data volumes continue to expand as they take in an ever-wider range of sources, much of which is in unstructured form. Organisations want to extract value from that data to uncover the opportunities for the business that it contains. But the centralised nature of big data stores creates new security challenges. Traditional tools are not, on their own, up to the task of processing the information the data contains, let alone ensuring it's secure in the process. Colin Tankard of Digital Pathways explains that controls need to be placed around the data itself, rather than the applications and systems that store the data.}
}

@inproceedings{bigDataSecurityHealthPatil2014,
  title={Big data security and privacy issues in healthcare},
  author={Patil, Harsh Kupwade and Seshadri, Ravi},
  booktitle={2014 IEEE international congress on big data},
  pages={762--765},
  year={2014},
  organization={IEEE}
}

@inproceedings{bigMetadataSmith2014,
author = {Smith, Ken and Seligman, Len and Rosenthal, Arnon and Kurcz, Chris and Greer, Mary and Macheret, Catherine and Sexton, Michael and Eckstein, Adric},
title = {"Big Metadata": The Need for Principled Metadata Management in Big Data Ecosystems},
year = {2014},
isbn = {9781450329972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2627770.2627776},
doi = {10.1145/2627770.2627776},
abstract = {Current big data ecosystems lack a principled approach to metadata management. This impedes large organizations' ability to share data and data preparation and analysis code, to integrate data, and to ensure that analytic code makes compatible assumptions with the data it uses. This use-case paper describes the challenges and an in-progress effort to address them. We present a real application example, discuss requirements for "big metadata" drawn from that example as well as other U.S. government analytic applications, and briefly describe an effort to adapt an existing open source metadata manager to support the needs of big data ecosystems.},
booktitle = {Proceedings of Workshop on Data Analytics in the Cloud},
pages = {1–4},
numpages = {4},
keywords = {data integration, metadata, Big data analytics, data discovery},
location = {Snowbird, UT, USA},
series = {DanaC'14}
}

@article{shimsNewton2011,
  title={Demystifying Shims-or-Using the App Compat Toolkit to make your old stuff work with your new stuff},
  author={Newton, T},
  journal={Jun},
  volume={17},
  pages={1--6},
  year={2011}
}

@inproceedings{nistRBAC2000Sandhu,
  title={The NIST model for role-based access control: towards a unified standard},
  author={Sandhu, Ravi and Ferraiolo, David and Kuhn, Richard and others},
  booktitle={ACM workshop on Role-based access control},
  volume={10, no. 344287.344301},
  year={2000}
}

 @misc{buildingAccessControlForOpenMetadata2022Mathew, 
    title={Building Access Control for OpenMetadata},
    url={https://blog.open-metadata.org/building-access-control-for-openmetadata-5b842a2abd90},
    editor={OpenMetadata},
    author={Mathew, Mithun},
    year={2022},
    month={Feb},
    note = {\href{https://blog.open-metadata.org/building-access-control-for-openmetadata-5b842a2abd90}{blog.open-metadata.com} {[Online; Accessed 10-March-2023]}},
} 
